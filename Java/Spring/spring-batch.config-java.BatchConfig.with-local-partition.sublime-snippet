<snippet>
  <content><![CDATA[
@Configuration
@EnableBatchProcessing
public class BatchConfig extends DefaultBatchConfigurer {

    public static final int CHUNK_SIZE = 100;
    public static final int CHUNK_SIZE_RDW = 500;

    @Autowired
    private JobBuilderFactory jobBuilderFactory;

    @Autowired
    private StepBuilderFactory stepBuilderFactory;

    @Autowired
    private RemoteFilesLookupService filesLookupService;

    @Autowired
    private SqlSessionFactory sqlSessionFactory;

    @Override
    public void setDataSource(DataSource dataSource) {
    }

    @Bean
    public TaskExecutor taskExecutor() {
        ThreadPoolTaskExecutor t = new ThreadPoolTaskExecutor();
        t.setCorePoolSize(4);
        t.setMaxPoolSize(4);
        // t.setQueueCapacity(50);
        t.setAllowCoreThreadTimeOut(true);
        t.setKeepAliveSeconds(120);
        return t;
    }

    @Bean(name = JOB_UVR_FILES_CHECK)
    public Job uvrFilesJob() throws IOException { // Rule
        return this.jobBuilderFactory.get(JOB_UVR_FILES_CHECK)
                .preventRestart()
                .start(partitioningUvrFileStep())
                .build();
    }

    @Bean
    public Step partitioningUvrFileStep() throws IOException {
        Step workingStep = uvrFileStep();
        return this.stepBuilderFactory.get("partitioningUvrFileStep")
                .partitioner(
                        workingStep.getName(),
                        uvrFileBasedPartitioner(null, null)
                )
                // .aggregator(new DefaultStepExecutionAggregator()) // By
                // Default
                .taskExecutor(taskExecutor())
                .step(workingStep)
                // The gridSize attribute determines the number of separate
                // step executions to create, so it can be matched to the
                // size of the thread pool in the TaskExecutor. Alternatively,
                // it can be set to be larger than the number of threads
                // available, which makes the blocks of work smaller.
                .gridSize(1)
                .build();
    }

    @Bean
    @StepScope
    public Partitioner uvrFileBasedPartitioner(
            @Value("#{jobParameters[date]}") String date,
            @Value("#{jobParameters[filePattern]}") String filePattern
    ) throws IOException {
        List<ResolvedFileWrapper> resolvedFileWrappers =
                filesLookupService.resolveFiles(date, filePattern);
        Resource[] resources = resolvedFileWrappers.stream()
                .map(wrapper ->
                        new FileSystemResource(wrapper.getResolvedFilePath()))
                .toArray(Resource[]::new);

        MultiResourcePartitioner multiResourcePartitioner =
                new MultiResourcePartitioner();
        multiResourcePartitioner.setResources(resources);

        return multiResourcePartitioner;
    }

    @Bean
    public Step uvrFileStep() {
        return this.stepBuilderFactory.get("uvrFileStep")
                .listener(rowCheckResultAggregator())
                .<Map<String, Object>, List<DQICheckResult>>chunk(CHUNK_SIZE)
                .reader(uvrFileItemReader(null))
                .processor(uvrRowChecker(null, null))
                .listener(rowCheckResultAggregator())
                .writer(uvrCheckResultWriter())
                .build();
    }

//    @Bean
//    public Tasklet getTasklet() {
//        return null;
//    }

//    @Bean
//    @StepScope
//    public MultiResourceItemReader<Map<String, Object>>
//    multiUvrFilesItemReader(
//            @Value("#{jobParameters[date]}") String date,
//            @Value("#{jobParameters[filePattern]}") String filePattern
//    ) throws IOException {
//        List<ResolvedFileWrapper> resolvedFileWrappers =
//                filesLookupService.resolveFiles(date, filePattern);
//        Resource[] resources = resolvedFileWrappers.stream()
//                .map(wrapper ->
//                        new FileSystemResource(wrapper.getResolvedFilePath()))
//                .toArray(Resource[]::new);
//
//        return new MultiResourceItemReaderBuilder<Map<String, Object>>()
//                .delegate(uvrFileItemReader())
//                .resources(resources)
//                .build();
//    }

    @Bean
    @StepScope
    public FlatFileItemReader<Map<String, Object>> uvrFileItemReader(
            @Value("#{stepExecutionContext['fileName']}") Resource resource
    ) {
        DelimitedLineTokenizer delimitedLineTokenizer =
                new DelimitedLineTokenizer(";");

        Map<String, FieldParser<?>> headerToFieldParser = new HashMap<>();
        headerToFieldParser.put("M_RESULTV", new PipeDelimitedFieldParser());
        UVRFieldSetMapper uvrFieldSetMapper =
                new UVRFieldSetMapper(headerToFieldParser);

        DefaultLineMapper<Map<String, Object>> lineMapper =
                new DefaultLineMapper<>();
        lineMapper.setLineTokenizer(delimitedLineTokenizer);
        lineMapper.setFieldSetMapper(uvrFieldSetMapper);

        return new FlatFileItemReaderBuilder<Map<String, Object>>()
                .name("uvrFileItemReader")
                .resource(resource)
                .bufferedReaderFactory(new UVRFileBufferedReaderFactory())
                .linesToSkip(1)
                .skippedLinesCallback(line ->
                        delimitedLineTokenizer.setNames(line.split(";")))
                .lineMapper(lineMapper)
                .build();
    }

    @Bean
    @StepScope
    public UVRRowChecker uvrRowChecker(
            @Value("#{jobParameters[fieldName]}") String fieldName,
            @Value("#{jobParameters[checkList]}") String serialisedCheckList
    ) {
        List<Check<?, ?>> checkList =
                CheckSerialiser.deserialiseCheckList(serialisedCheckList);
        return new UVRRowChecker(fieldName, checkList);
    }

    @Bean
    @StepScope
    public DQIRowCheckResultAggregator rowCheckResultAggregator() {
        return new DQIRowCheckResultAggregator();
    }

    @Bean
    @StepScope
    public UVRRowCheckResultWriter uvrCheckResultWriter() {
        return new UVRRowCheckResultWriter();
    }

    @Bean(name = JOB_RDW_DATA_CHECK)
    public Job rdwDataJob() { // Rule
        return this.jobBuilderFactory.get(JOB_RDW_DATA_CHECK)
                .preventRestart()
                .start(rdw10DayDataAtRiskStep())
                .build();
    }

    @Bean
    public Step rdw10DayDataAtRiskStep() {
        return this.stepBuilderFactory.get("rdw10DayDataAtRiskStep")
                .listener(rowCheckResultAggregator())
                .<Map<String, Object>, List<DQICheckResult>>
                        chunk(CHUNK_SIZE_RDW)
                .reader(rdw10DayDataAtRiskReader(null, null))
                .processor(rdw10DayDataAtRiskItemChecker(null))
                .listener(rowCheckResultAggregator())
                .writer(rdwRowCheckResultWriter())
                .build();
    }

    @Bean
    @StepScope
    public MyBatisPagingItemReader<Map<String, Object>> rdw10DayDataAtRiskReader(
            @Value("#{jobParameters[date]}") String date,
            @Value("#{jobParameters[isNormalVarNotStressVar]}") Boolean isNormalVarNotStressVar
    ) {
        String prevDay = getDayBefore(date);

        Map<String, Object> params = new HashMap<>();
        params.put("today", date);
        params.put("prevDay", prevDay);
        params.put("isNormalVarNotStressVar", isNormalVarNotStressVar ? 1 : 0);

        return new MyBatisPagingItemReaderBuilder<Map<String, Object>>()
                .sqlSessionFactory(sqlSessionFactory)
                .queryId(String.join(".",
                        CapitalMultiplierVarMapper.class.getCanonicalName(),
                        "get10DayDataAtRisk"))
                .parameterValues(params)
                .pageSize(CHUNK_SIZE_RDW)
                .build();
    }

    @Bean
    @StepScope
    public RDW10DayDataAtRiskRowChecker rdw10DayDataAtRiskItemChecker(
            @Value("#{jobParameters[checkList]}") String serialisedCheckList
    ) {
        List<Check<?, ?>> checkList =
                CheckSerialiser.deserialiseCheckList(serialisedCheckList);
        return new RDW10DayDataAtRiskRowChecker(checkList);
    }

    @Bean
    @StepScope
    public RDWRowCheckResultWriter rdwRowCheckResultWriter() {
        return new RDWRowCheckResultWriter();
    }

}
]]></content>
  <!-- Optional: Set a tabTrigger to define how to trigger the snippet -->
  <tabTrigger>spring-batch.config-java.BatchConfig.with-local-partition</tabTrigger>
  <!-- Optional: Set a scope to limit where the snippet will trigger -->
  <scope>source.java, text.plain</scope>
</snippet>
